{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from pandas_plink import read_plink\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "tfrecords_opts =  tf.python_io.TFRecordOptions(tf.python_io.TFRecordCompressionType.ZLIB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in the PLINK data into a dask/pandas data structures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Mapping files: 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n"
     ]
    }
   ],
   "source": [
    "plink_file = 'data/large_test'\n",
    "bim, fam, G = read_plink(plink_file)\n",
    "G = np.array(G.T, dtype=np.int8)\n",
    "G.fillna(0, inplace=True)\n",
    "N = G.shape[0]\n",
    "M = G.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a .tfrecords file for the genotype matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_record(row, writer_handle):\n",
    "    '''\n",
    "    row: a sample's genotype vector.\n",
    "    '''\n",
    "    # wrap raw byte values\n",
    "    genotypes_feature = tf.train.Feature(\n",
    "        bytes_list=tf.train.BytesList(value=[row.tostring()]))\n",
    "\n",
    "    # convert to Example\n",
    "    example = tf.train.Example(\n",
    "        features=tf.train.Features(\n",
    "            feature={'genotypes': genotypes_feature}))\n",
    "\n",
    "    writer_handle.write(example.SerializeToString())\n",
    "\n",
    "with tf.python_io.TFRecordWriter('data/test.tfrecords', options=tfrecords_opts) as tfwriter:\n",
    "    np.apply_along_axis(write_record, axis=1, arr=G, writer_handle=tfwriter)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a decoder for the .tfrecords file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_tfrecords(tfrecords_filename, m_variants):\n",
    "    '''\n",
    "    Parse a tf.string pointing to *.tfrecords into a genotype tensor,  rows: variants, cols: samples)\n",
    "    Helpful blog post:\n",
    "    http://warmspringwinds.github.io/tensorflow/tf-slim/2016/12/21/tfrecords-guide/\n",
    "    '''\n",
    "    data = tf.parse_example([tfrecords_filename],\n",
    "        {'genotypes': tf.FixedLenFeature([], tf.string)})\n",
    "\n",
    "    gene_vector = tf.decode_raw(data['genotypes'], tf.int8)\n",
    "    gene_vector = tf.reshape(gene_vector, [1, m_variants])\n",
    "\n",
    "    return gene_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check our that the decoded results match the input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    dataset = tf.data.TFRecordDataset('data/test.tfrecords', compression_type=tf.constant('ZLIB'))\n",
    "    dataset = dataset.map(lambda fn: decode_tfrecords(fn, M))\n",
    "    iterator = dataset.make_one_shot_iterator()\n",
    "    x = iterator.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2 2 1 1 2 2 2 2 2 1 2 0 2 2 2 1 2 2 1 1 1 0 1 2 2 2 1 1 1 2 2 1 1 0 1 2\n",
      "  2 1 1 2 2 2 2 2 1 2 2 2 2 2 1 2 2 1 1 2 2 2 2 1 1 1 1 1 2 1 1 2 2 2 2 2\n",
      "  2 2 2 1 1 1 1 1 2 1 2 2 1 2 1 2 1 2 1 2 2 1 1 2 2 1 1 2 1 2 2 2 1 1 1 1\n",
      "  2 1 1 1 1 2 1 2 2 2 2 2 2 2 0 2 1 2 2 1 2 1 2 0 1 2 2 1 2 2 1 2 2 2 2 2\n",
      "  1 1 2 1 2 1 1 1 2 2 1 1 1 0 2 2 2 0 1 1 2 2 2 2 2 2 2 1 2 2 1 1 1 2 2 2\n",
      "  2 2 2 1 1 2 2 2 1 2 1 2 1 1 2 1 1 1 1 1 1 1 1 2 1 1 1 1 2 2 0 0 2 2 2 2\n",
      "  2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 1 2 2 2 2 1 2 1 1 2 1 1\n",
      "  1 1 2 1 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 0 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      "  2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 1 2 1 1 2 2 1 2 2 2 1 1 1 2 2 1 1 1 2\n",
      "  2 1 2 0 2 1 2 1 2 1 1 2 2 1 2 1 1 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 1 2 2\n",
      "  2 1 2 1 2 2 2 2 2 1 1 0 1 0 1 1 1 1 2 2 2 1 0 2 2 1 1 1 0 2 0 1 2 0 1 2\n",
      "  2 1 2 1 1 2 2 1 2 1 1 2 1 1 1 2 2 1 1 1 2 2 2 1 1 2 2 2 1 1 1 1 1 2 1 2\n",
      "  1 1 2 1 2 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 2 1 1 2 1 1 1 2 2\n",
      "  2 2 2 1 1 2 2 2 1 2 0 2 2 2 2 2 1 2 2 0 2 2 2 2 0 2 2 2 0 2 0 0 2 0 2 0\n",
      "  2 0 0 2 0 2 2 2 2 0 2 0 2 0 0 2 2 0 2 2 1 1 1 1 2 1 1 2 1 2 2 2 2 1 2 2\n",
      "  1 1 2 2 2 2 2 1 2 2 2 2 2 2 2 0 2 2 2 2 2 2 2 2 2 2 2 0 2 2 2 2 2 2 2 0\n",
      "  2 2 2 0 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 2 1 2 2 2 2 1 2 1 2 1 1\n",
      "  1 2 2 1 2 1 1 2 1 1 2 2 2 1 2 1 2 0 2 0 2 2 2 2 0 1 1 2 1 1 1 2 1 1 1 2\n",
      "  1 1 2 1 2 1 2 1 2 2 2 1 2 1 2 1 2 2 1 1 1 2 2 2 1 2 2 2 2 2 2 2 2 0 2 2\n",
      "  2 0 2 2 2 2 2 1 2 2 2 2 0 2 2 0 2 2 2 2 2 2 2 1 0 0 2 1 1 1 2 2 1 1 1 1\n",
      "  2 1 1 2 2 2 1 1 1 2 2 2 1 2 1 2 1 2 2 2 2 1 0 1 1 2 1 1 2 2 2 2 2 2 1 1\n",
      "  2 2 1 1 1 2 2 2 2 2 1 2 0 2 2 2 2 2 0 2 2 2 2 2 0 2 2 1 1 2 2 2 2 2 2 2\n",
      "  1 1 2 1 2 1 1 2 1 2 1 2 1 2 2 1 2 2 1 2 2 1 1 2 2 1 2 1 2 2 1 2 2 1 1 1\n",
      "  2 1 2 2 1 1 2 2 2 2 2 2 1 1 1 2 0 2 2 2 2 2 0 2 0 1 1 1 2 1 1 1 2 2 1 0\n",
      "  0 2 2 0 2 2 0 2 2 2 2 2 0 0 2 0 2 0 2 2 2 2 2 0 2 0 2 2 2 2 2 2 2 2 2 2\n",
      "  2 2 2 2 2 2 2 2 2 1 2 2 1 1 1 1 2 2 1 2 2 1 1 2 1 1 2 2 1 1 1 2 1 1 1 2\n",
      "  1 2 1 2 1 2 1 1 1 2 2 1 1 2 1 1 1 2 1 2 2 1 2 2 2 2 1 2 1 2 2 2 2 0 0 0\n",
      "  0 2 2 2 2 2 2 0 2 0 2 2 0 0 2 0 0 0 1 2 2 2 2 1 1 2 1 2]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(graph=graph) as sess:\n",
    "    decoded_rec = sess.run(x)\n",
    "    print(decoded_rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
